services:
  # PostgreSQL with pgvector extension
  postgres:
    image: pgvector/pgvector:pg16
    container_name: intelidoc-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-intelidoc}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-intelidoc_secret}
      POSTGRES_DB: ${POSTGRES_DB:-intelidoc}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "6584:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-intelidoc} -d ${POSTGRES_DB:-intelidoc}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Ollama - Local LLM server with GPU support
  ollama:
    image: ollama/ollama:latest
    container_name: intelidoc-ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # Docling Service - Document processing with GPU
  docling:
    build:
      context: .
      dockerfile: Dockerfile.docling
    container_name: intelidoc-docling
    volumes:
      - ./uploads:/app/uploads
      - docling_cache:/root/.cache
    ports:
      - "8001:8001"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8001/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # RAG API Service
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: intelidoc-api
    volumes:
      - ./app:/app/app
      - ./uploads:/app/uploads
      - model_cache:/root/.cache
    ports:
      - "9060:9060"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-intelidoc}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-intelidoc_secret}
      - POSTGRES_DB=${POSTGRES_DB:-intelidoc}
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - DOCLING_HOST=http://docling:8001
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-384}
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_API_BASE=${OPENAI_API_BASE:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-2.0-flash-exp}
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
      docling:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9060/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    restart: unless-stopped

volumes:
  postgres_data:
  ollama_data:
  docling_cache:
  model_cache:

networks:
  default:
    name: intelidoc-network
